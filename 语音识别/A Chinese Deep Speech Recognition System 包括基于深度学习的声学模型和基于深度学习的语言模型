https://github.com/audier/DeepSpeechRecognition

A Chinese Deep Speech Recognition System 包括基于深度学习的声学模型和基于深度学习的语言模型

基于深度学习的中文语音识别系统
GPL-3.0 Licensed TensorFlow Version Keras Version Python Version

如果觉得有用的话，小手给个star吧~

注意：本人于近期想对该项目进行翻新，tf现在已经将keras作为重要的一部分，因此可能将代码用TensorFlow2来进行修改。大家有什么建议可以在issue提一下。
Note: I want to refurbish the project in the near future. tf now has keras as an important part, so the code may be modified with TensorFlow2. Any suggestions for everyone can be mentioned in the issue.
1. Introduction
该系统实现了基于深度框架的语音识别中的声学模型和语言模型建模，其中声学模型包括CNN-CTC、GRU-CTC、CNN-RNN-CTC，语言模型包含transformer、CBHG，数据集包含stc、primewords、Aishell、thchs30四个数据集。

本系统更整体介绍：https://blog.csdn.net/chinatelecom08/article/details/82557715

本项目现已训练一个迷你的语音识别系统，将项目下载到本地上，下载thchs数据集并解压至data，运行test.py，不出意外能够进行识别，结果如下：

 the  0 th example.
文本结果： lv4 shi4 yang2 chun1 yan1 jing3 da4 kuai4 wen2 zhang1 de di3 se4 si4 yue4 de lin2 luan2 geng4 shi4 lv4 de2 xian1 huo2 xiu4 mei4 shi1 yi4 ang4 ran2
原文结果： lv4 shi4 yang2 chun1 yan1 jing3 da4 kuai4 wen2 zhang1 de di3 se4 si4 yue4 de lin2 luan2 geng4 shi4 lv4 de2 xian1 huo2 xiu4 mei4 shi1 yi4 ang4 ran2
原文汉字： 绿是阳春烟景大块文章的底色四月的林峦更是绿得鲜活秀媚诗意盎然
识别结果： 绿是阳春烟景大块文章的底色四月的林峦更是绿得鲜活秀媚诗意盎然
若自己建立模型则需要删除现有模型，重新配置参数训练，具体实现流程参考本页最后。

2. 声学模型
声学模型采用CTC进行建模，采用CNN-CTC、GRU-CTC、FSMN等模型model_speech，采用keras作为编写框架。

论文地址：http://www.infocomm-journal.com/dxkx/CN/article/openArticlePDFabs.jsp?id=166970

tutorial：https://blog.csdn.net/chinatelecom08/article/details/85013535

3. 语言模型
新增基于self-attention结构的语言模型model_language\transformer.py，该模型已经被证明有强于其他框架的语言表达能力。

论文地址：https://arxiv.org/abs/1706.03762。

tutorial：https://blog.csdn.net/chinatelecom08/article/details/85051817

基于CBHG结构的语言模型model_language\cbhg.py，该模型之前用于谷歌声音合成，移植到该项目中作为基于神经网络的语言模型。

原理地址：https://github.com/crownpku/Somiao-Pinyin

tutorial：https://blog.csdn.net/chinatelecom08/article/details/85048019

4. 数据集
包括stc、primewords、Aishell、thchs30四个数据集，共计约430小时, 相关链接：http://www.openslr.org/resources.php

Name	train	dev	test
aishell	120098	14326	7176
primewords	40783	5046	5073
thchs-30	10000	893	2495
st-cmd	10000	600	2000
数据标签整理在data路径下，其中primewords、st-cmd目前未区分训练集测试集。

若需要使用所有数据集，只需解压到统一路径下，然后设置utils.py中datapath的路径即可。

与数据相关参数在utils.py中：

data_type: train, test, dev
data_path: 对应解压数据的路径
thchs30, aishell, prime, stcmd: 是否使用该数据集
batch_size: batch_size
data_length: 我自己做实验时写小一些看效果用的，正常使用设为None即可
shuffle：正常训练设为True，是否打乱训练顺序
def data_hparams():
    params = tf.contrib.training.HParams(
        # vocab
        data_type = 'train',
        data_path = 'data/',
        thchs30 = True,
        aishell = True,
        prime = False,
        stcmd = False,
        batch_size = 1,
        data_length = None,
        shuffle = False)
      return params
5. 配置
使用train.py文件进行模型的训练。

声学模型可选cnn-ctc、gru-ctc，只需修改导入路径即可：

from model_speech.cnn_ctc import Am, am_hparams

from model_speech.gru_ctc import Am, am_hparams

语言模型可选transformer和cbhg:

from model_language.transformer import Lm, lm_hparams

from model_language.cbhg import Lm, lm_hparams

模型识别
使用test.py检查模型识别效果。 模型选择需和训练一致。

一个简单的例子
1. 声学模型训练
train.py文件

import os
import tensorflow as tf
from utils import get_data, data_hparams


# 准备训练所需数据
data_args = data_hparams()
data_args.data_length = 10
train_data = get_data(data_args)


# 1.声学模型训练-----------------------------------
from model_speech.cnn_ctc import Am, am_hparams
am_args = am_hparams()
am_args.vocab_size = len(train_data.am_vocab)
am = Am(am_args)
if os.path.exists('logs_am/model.h5'):
    print('load acoustic model...')
    am.ctc_model.load_weights('logs_am/model.h5')

epochs = 10
batch_num = len(train_data.wav_lst) // train_data.batch_size

for k in range(epochs):
    print('this is the', k+1, 'th epochs trainning !!!')
    #shuffle(shuffle_list)
    batch = train_data.get_am_batch()
    am.ctc_model.fit_generator(batch, steps_per_epoch=batch_num, epochs=1)

am.ctc_model.save_weights('logs_am/model.h5')
