版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。
本文链接：https://blog.csdn.net/shangpapa3/article/details/76277869
不知道大家有没有遇到和我一样的问题，最终解决了。最初训练的时候大概阈值设到0.008才会有框框出来，跟自带的权重相比相差好多啊，默认阈值应该等于0.25才对啊！真的是被困扰了很久，还跑去修改了yolo.c文件（其实一点关系也没有），最后发现过于相信依赖官网给出的步骤，没有仔细看一下文件，导致了这个错误，问题很白痴，源于cfg文件。

１下载 voc数据集
curl -O https://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar
curl -O https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar
curl -O https://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar
tar xf VOCtrainval_11-May-2012.tar
tar xf VOCtrainval_06-Nov-2007.tar
tar xf VOCtest_06-Nov-2007.tar
1
2
3
4
5
6
这里我新建了文件夹pjreddie。在该文件夹下运行，出现了VOCdevkit文件夹。

curl -O https://pjreddie.com/media/files/voc_label.py
python voc_label.py
1
2
依然在该文件夹下运行，稍微等一下就好了。

ls
1


出现的结果与官网相同。

２修改文件
./cfg/voc.data 和./cfg/yolo-voc.cfg



这里十分需要注意的一点！！有许多模型可以选择。



最初选择的是yolo-voc.cfg，官网没有提到要对它进行修改，但是往下翻训练coco数据集时提到了一下。



所以，我们现在是训练，当然要引掉测试了，batch和subdivisions测试时等于1，放在训练里肯定是不行的，难以收敛。这里简单说一下。

每batch个样本更新一次参数，如果内存不够大，将batch分割为subdivisions个子batch，每个子batch的大小为batch/subdivisions，在darknet代码中，会将batch/subdivisions命名为batch。

在合理范围内，增大 Batch_Size 有何好处？

内存利用率提高了，大矩阵乘法的并行化效率提高。
跑完一次 epoch（全数据集）所需的迭代次数减少，对于相同数据量的处理速度进一步加快。
在一定范围内，一般来说 Batch_Size 越大，其确定的下降方向越准，引起训练震荡越小。
1
2
3
盲目增大 Batch_Size 有何坏处？

内存利用率提高了，但是内存容量可能撑不住了。
跑完一次 epoch（全数据集）所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。
Batch_Size 增大到一定程度，其确定的下降方向已经基本不再变化。
1
2
3
这里用的依然是它设定的值。
————————————————
版权声明：本文为CSDN博主「尚爬爬」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/shangpapa3/article/details/76277869
